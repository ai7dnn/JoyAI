15조 최종 보고서 (유수민, 전혜림)
[1] 예비보고서


1. 프로젝트 제목


CNN을 이용한 수화인식

2. 프로젝트 시작 계기


발전하고 변화하는 IT 기술들은 빠른 변화에 집중하고 있지만 청각장애인, 시각장애인 등 IT기술에 소외된 많은 사람들을 충분히 고려하고 있진 않습니다. 최근 들어 더욱 관심이 집중되고 있는 머신러닝, 컴퓨터 비전 등의 분야를 통해 소외된 이들에게 어떤 도움을 줄 수 있을까 생각해보게 되었고 수화 데이터셋을 발견하게 되었습니다. CNN을 이용한 수화 인식기술과 사용되는 시각적 인식 알고리즘은 최신 기계 학습 방법에 도전하며 청각 장애인과 난청인들이 컴퓨터 비전 애플리케이션을 사용하여 더 잘 의사 소통할 수 있도록 실용적으로 도울 수 있을 것입니다. 또한 Text to speech의 개선된 버전으로 수화 자동번역에도 도움이 될 것입니다. IT 기술의 발전과 보급이 외국어 번역을 수월하게 해 세계간의 거리를 좁히고 있다면 가까이에 있는 청각장애인들과 사람들과의 거리가 좁히는 것도 IT 기술의 발전이 이끌어 내야 하는 일이라고 생각하여 이 프로젝트를 선택하게 되었습니다.

3. 프로젝트 개요


이 프로젝트는 다음 출처를 바탕으로 진행됩니다.
           프로젝트(https://www.kaggle.com/madz2000/cnn-using-keras-100-accuracy/notebook)

           데이터 셋(https://www.kaggle.com/datamunge/sign-language-mnist)

데이터 시각화 및 전처리
데이터 증강(overfitting을 피하기 위해)
CNN을 이용하여 모델 훈련
훈련결과 분석
4. 기대효과

수화를 모르는 사람들도 이미지를 통해 해당 손동작이 어떤 알파벳인지를 알 수 있어 수화를 하는 사람과 수화를 모르는 사람 간의 소통이 가능해질 것입니다.
더 나아가 이미지 뿐만 아니라 영상에 이 기술을 적용할 수 있게 된다면 실시간으로 수화를 해석할 수 있어 소통에 큰 도움이 될 수 있을 것입니다.
[2] 프로젝트 작업파일

Data : sign_mnist_train_test.zip
Source code : CNN_sign_language_source_code.ipynb
PPT : CNN_sign_language_ppt.pptx
[3] 동영상 발표 Link


https://youtu.be/MXmTKyv8liw